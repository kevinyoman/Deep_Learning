padding = "same",
activation = "relu",
input_shape = c(target_size, 3)
) %>%
# First convolutional layer
layer_conv_2d(filters = 64,
kernel_size = c(3,3), # 3 x 3 filters
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Third convolutional layer
layer_conv_2d(filters = 128,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Third convolutional layer
layer_conv_2d(filters = 128,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Fourth convolutional layer
layer_conv_2d(filters = 256,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Fifth convolutional layer
layer_conv_2d(filters = 512,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Flattening layer
layer_flatten() %>%
# Dense layer
layer_dense(units = 4096,
activation = "relu") %>%
# Dense layer
layer_dense(units = 2048,
activation = "relu") %>%
# Dense layer
layer_dense(units = 1024,
activation = "relu") %>%
# Output layer
layer_dense(name = "Output",
units = 3,
activation = "softmax")
model
model %>%
compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(lr = 0.001),
metrics = "accuracy"
)
## install pillow & SciPy in python environment
# Fit data into model
history <- model %>%
fit_generator(
# training data
train_image_array_gen,
# training epochs
steps_per_epoch = as.integer(train_samples / batch_size),
epochs = 51, #65
# validation data
validation_data = val_image_array_gen,
validation_steps = as.integer(valid_samples / batch_size)
)
plot(history)
val_data <- data.frame(file_name = paste0("train/", val_image_array_gen$filenames)) %>%
mutate(class = str_extract(file_name, "beach|forest|mountain"))
tail(val_data, 10)
# Function to convert image to array
image_prep <- function(x) {
arrays <- lapply(x, function(path) {
img <- image_load(path, target_size = target_size,
grayscale = F # Set FALSE if image is RGB
)
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
x <- x/255 # rescale image pixel
})
do.call(abind::abind, c(arrays, list(along = 1)))
}
test_x <- image_prep(val_data$file_name)
# Check dimension of testing data set
dim(test_x)
pred_test <- predict_classes(model, test_x)
head(pred_test, 10)
# Convert encoding to label
decode <- function(x){
case_when(x == 0 ~ "beach",
x == 1 ~ "forest",
x == 2 ~ "mountain"
)
}
pred_test <- sapply(pred_test, decode)
head(pred_test, 10)
confusionMatrix(as.factor(pred_test),
as.factor(val_data$class),
mode = "everything"
)
folder_list_test <- list.files("test/")
filename_test <- paste0("test/", folder_list_test)
test_x_real <- image_prep(filename_test)
pred_test_real <- predict_classes(model, test_x_real)
pred_test_real <- sapply(pred_test_real, decode)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(imager)
library(keras)
library(caret)
folder_list <- list.files("train/")
folder_list
folder_path <- paste0("train/", folder_list, "/")
folder_path
file_name <- map(folder_path,
function(x) paste0(x, list.files(x))
) %>%
unlist()
length(file_name)
# Full Image Description
img <- load.image(file_name[1])
# img
dim(img)
# Function for acquiring width and height of an image
get_dim <- function(x){
img <- load.image(x)
df_img <- data.frame(height = height(img),
width = width(img),
filename = x
)
return(df_img)
}
get_dim(file_name[1])
# # Randomly get 1000 sample images
#  set.seed(201)
#  sample_file <- sample(file_name, 1000)
#
# # Run the get_dim() function for each image
#  file_dim <- map_df(sample_file, get_dim)
#
#  head(file_dim, 10)
# summary(file_dim)
# Desired height and width of images
target_size <- c(64, 64)
# Batch size for training the model
batch_size <- 32
# Image Generator
train_data_gen <- image_data_generator(rescale = 1/255, # Scaling pixel value
horizontal_flip = T, # Flip image horizontally
vertical_flip = T, # Flip image vertically
rotation_range = 45, # Rotate image from 0 to 45 degrees
zoom_range = 0.25, # Zoom in or zoom out range
validation_split = 0.2 # 20% data as validation data
)
# Training Dataset
train_image_array_gen <- flow_images_from_directory(directory = "train/", # Folder of the data
target_size = target_size, # target of the image dimension (160 x 260)
color_mode = "rgb", # use RGB color
batch_size = batch_size ,
seed = 201,  # set random seed
subset = "training", # declare that this is for training data
generator = train_data_gen
)
# Validation Dataset
val_image_array_gen <- flow_images_from_directory(directory = "train/",
target_size = target_size,
color_mode = "rgb",
batch_size = batch_size ,
seed = 201,
subset = "validation", # declare that this is the validation data
generator = train_data_gen
)
# Number of training samples
train_samples <- train_image_array_gen$n
# Number of validation samples
valid_samples <- val_image_array_gen$n
# Number of target classes/categories
output_n <- n_distinct(train_image_array_gen$classes)
# Get the class proportion
table("\nFrequency" = factor(train_image_array_gen$classes)
) %>%
prop.table()
# input shape of the image
c(target_size, 3)
# Set Initial Random Weight
tensorflow::tf$random$set_seed(201)
model <- keras_model_sequential() %>%
# First convolutional layer
layer_conv_2d(filters = 64,
kernel_size = c(3,3), # 3 x 3 filters
padding = "same",
activation = "relu",
input_shape = c(target_size, 3)
) %>%
# First convolutional layer
layer_conv_2d(filters = 64,
kernel_size = c(3,3), # 3 x 3 filters
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Third convolutional layer
layer_conv_2d(filters = 128,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Third convolutional layer
layer_conv_2d(filters = 128,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Fourth convolutional layer
layer_conv_2d(filters = 256,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Fifth convolutional layer
layer_conv_2d(filters = 512,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Flattening layer
layer_flatten() %>%
# Dense layer
layer_dense(units = 4096,
activation = "relu") %>%
# Dense layer
layer_dense(units = 4096,
activation = "relu") %>%
# Dense layer
layer_dense(units = 1024,
activation = "relu") %>%
# Output layer
layer_dense(name = "Output",
units = 3,
activation = "softmax")
model
model %>%
compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(lr = 0.001),
metrics = "accuracy"
)
## install pillow & SciPy in python environment
# Fit data into model
history <- model %>%
fit_generator(
# training data
train_image_array_gen,
# training epochs
steps_per_epoch = as.integer(train_samples / batch_size),
epochs = 51, #65
# validation data
validation_data = val_image_array_gen,
validation_steps = as.integer(valid_samples / batch_size)
)
plot(history)
val_data <- data.frame(file_name = paste0("train/", val_image_array_gen$filenames)) %>%
mutate(class = str_extract(file_name, "beach|forest|mountain"))
tail(val_data, 10)
# Function to convert image to array
image_prep <- function(x) {
arrays <- lapply(x, function(path) {
img <- image_load(path, target_size = target_size,
grayscale = F # Set FALSE if image is RGB
)
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
x <- x/255 # rescale image pixel
})
do.call(abind::abind, c(arrays, list(along = 1)))
}
test_x <- image_prep(val_data$file_name)
# Check dimension of testing data set
dim(test_x)
pred_test <- predict_classes(model, test_x)
head(pred_test, 10)
# Convert encoding to label
decode <- function(x){
case_when(x == 0 ~ "beach",
x == 1 ~ "forest",
x == 2 ~ "mountain"
)
}
pred_test <- sapply(pred_test, decode)
head(pred_test, 10)
confusionMatrix(as.factor(pred_test),
as.factor(val_data$class),
mode = "everything"
)
folder_list_test <- list.files("test/")
filename_test <- paste0("test/", folder_list_test)
test_x_real <- image_prep(filename_test)
pred_test_real <- predict_classes(model, test_x_real)
pred_test_real <- sapply(pred_test_real, decode)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(imager)
library(keras)
library(caret)
folder_list <- list.files("train/")
folder_list
folder_path <- paste0("train/", folder_list, "/")
folder_path
file_name <- map(folder_path,
function(x) paste0(x, list.files(x))
) %>%
unlist()
length(file_name)
# Full Image Description
img <- load.image(file_name[1])
# img
dim(img)
# Function for acquiring width and height of an image
get_dim <- function(x){
img <- load.image(x)
df_img <- data.frame(height = height(img),
width = width(img),
filename = x
)
return(df_img)
}
get_dim(file_name[1])
# # Randomly get 1000 sample images
#  set.seed(201)
#  sample_file <- sample(file_name, 1000)
#
# # Run the get_dim() function for each image
#  file_dim <- map_df(sample_file, get_dim)
#
#  head(file_dim, 10)
# summary(file_dim)
# Desired height and width of images
target_size <- c(64, 64)
# Batch size for training the model
batch_size <- 32
# Image Generator
train_data_gen <- image_data_generator(rescale = 1/255, # Scaling pixel value
horizontal_flip = T, # Flip image horizontally
vertical_flip = T, # Flip image vertically
rotation_range = 45, # Rotate image from 0 to 45 degrees
zoom_range = 0.25, # Zoom in or zoom out range
validation_split = 0.2 # 20% data as validation data
)
# Training Dataset
train_image_array_gen <- flow_images_from_directory(directory = "train/", # Folder of the data
target_size = target_size, # target of the image dimension (160 x 260)
color_mode = "rgb", # use RGB color
batch_size = batch_size ,
seed = 201,  # set random seed
subset = "training", # declare that this is for training data
generator = train_data_gen
)
# Validation Dataset
val_image_array_gen <- flow_images_from_directory(directory = "train/",
target_size = target_size,
color_mode = "rgb",
batch_size = batch_size ,
seed = 201,
subset = "validation", # declare that this is the validation data
generator = train_data_gen
)
# Number of training samples
train_samples <- train_image_array_gen$n
# Number of validation samples
valid_samples <- val_image_array_gen$n
# Number of target classes/categories
output_n <- n_distinct(train_image_array_gen$classes)
# Get the class proportion
table("\nFrequency" = factor(train_image_array_gen$classes)
) %>%
prop.table()
# input shape of the image
c(target_size, 3)
# Set Initial Random Weight
tensorflow::tf$random$set_seed(201)
model <- keras_model_sequential() %>%
# First convolutional layer
layer_conv_2d(filters = 64,
kernel_size = c(3,3), # 3 x 3 filters
padding = "same",
activation = "relu",
input_shape = c(target_size, 3)
) %>%
# First convolutional layer
layer_conv_2d(filters = 64,
kernel_size = c(3,3), # 3 x 3 filters
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Third convolutional layer
layer_conv_2d(filters = 128,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Fourth convolutional layer
layer_conv_2d(filters = 256,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Fifth convolutional layer
layer_conv_2d(filters = 512,
kernel_size = c(3,3),
padding = "same",
activation = "relu"
) %>%
# Max pooling layer
layer_max_pooling_2d(pool_size = c(2,2)) %>%
# Flattening layer
layer_flatten() %>%
# Dense layer
layer_dense(units = 4096,
activation = "relu") %>%
# Dense layer
layer_dense(units = 4096,
activation = "relu") %>%
# Dense layer
layer_dense(units = 1000,
activation = "relu") %>%
# Output layer
layer_dense(name = "Output",
units = 3,
activation = "softmax")
model
model %>%
compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(lr = 0.001),
metrics = "accuracy"
)
## install pillow & SciPy in python environment
# Fit data into model
history <- model %>%
fit_generator(
# training data
train_image_array_gen,
# training epochs
steps_per_epoch = as.integer(train_samples / batch_size),
epochs = 51, #65
# validation data
validation_data = val_image_array_gen,
validation_steps = as.integer(valid_samples / batch_size)
)
plot(history)
val_data <- data.frame(file_name = paste0("train/", val_image_array_gen$filenames)) %>%
mutate(class = str_extract(file_name, "beach|forest|mountain"))
tail(val_data, 10)
# Function to convert image to array
image_prep <- function(x) {
arrays <- lapply(x, function(path) {
img <- image_load(path, target_size = target_size,
grayscale = F # Set FALSE if image is RGB
)
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
x <- x/255 # rescale image pixel
})
do.call(abind::abind, c(arrays, list(along = 1)))
}
test_x <- image_prep(val_data$file_name)
# Check dimension of testing data set
dim(test_x)
pred_test <- predict_classes(model, test_x)
head(pred_test, 10)
# Convert encoding to label
decode <- function(x){
case_when(x == 0 ~ "beach",
x == 1 ~ "forest",
x == 2 ~ "mountain"
)
}
pred_test <- sapply(pred_test, decode)
head(pred_test, 10)
confusionMatrix(as.factor(pred_test),
as.factor(val_data$class),
mode = "everything"
)
folder_list_test <- list.files("test/")
filename_test <- paste0("test/", folder_list_test)
test_x_real <- image_prep(filename_test)
pred_test_real <- predict_classes(model, test_x_real)
pred_test_real <- sapply(pred_test_real, decode)
